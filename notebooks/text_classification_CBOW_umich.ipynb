{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:36.509211Z",
     "start_time": "2018-07-09T02:32:35.930744Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import collections\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:49.292000Z",
     "start_time": "2018-07-09T02:32:48.001145Z"
    }
   },
   "outputs": [],
   "source": [
    "word_freq = collections.Counter()\n",
    "max_len = 0\n",
    "num_rec = 0\n",
    "\n",
    "with open('../data/umich-sentiment-train.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        label, sentence = line.decode('utf8').strip().split('\\t')\n",
    "        words = nltk.word_tokenize(sentence.lower())\n",
    "        if len(words) > max_len:\n",
    "            max_len = len(words)\n",
    "        for word in words:\n",
    "            word_freq[word] += 1\n",
    "        num_rec += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:50.219676Z",
     "start_time": "2018-07-09T02:32:50.205590Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_FEATURES = 2000\n",
    "MAX_SENTENCE_LENGTH = 40\n",
    "# most_common output -> list\n",
    "word2idx = {x[0]: i+2 for i, x in enumerate(word_freq.most_common(MAX_FEATURES - 2))}\n",
    "word2idx ['PAD'] = 0\n",
    "word2idx['UNK'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:51.009574Z",
     "start_time": "2018-07-09T02:32:51.005281Z"
    }
   },
   "outputs": [],
   "source": [
    "idx2word= {i:v for v, i in word2idx.items()}\n",
    "vocab_size = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:53.128199Z",
     "start_time": "2018-07-09T02:32:51.767573Z"
    }
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "x = []\n",
    "origin_txt = []\n",
    "with open('../data/umich-sentiment-train.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        _label, _sentence = line.decode('utf8').strip().split('\\t')\n",
    "        origin_txt.append(_sentence)\n",
    "        y.append(int(_label))\n",
    "        words = nltk.word_tokenize(_sentence.lower())\n",
    "        _seq = []\n",
    "        for word in words:\n",
    "            if word in word2idx.keys():\n",
    "                _seq.append(word2idx[word])\n",
    "            else:\n",
    "                _seq.append(word2idx['UNK'])\n",
    "        if len(_seq) < MAX_SENTENCE_LENGTH:\n",
    "            _seq.extend([0] * ((MAX_SENTENCE_LENGTH) - len(_seq)))\n",
    "        else:\n",
    "            _seq = _seq[:MAX_SENTENCE_LENGTH]\n",
    "        x.append(_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:32:58.902758Z",
     "start_time": "2018-07-09T02:32:58.855252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yn</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yn  index\n",
       "0   0   3091\n",
       "1   1   3995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y, columns = ['yn']).reset_index().groupby('yn').count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence representation: Average of BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:01.697120Z",
     "start_time": "2018-07-09T02:33:01.693872Z"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot(x, vocab_size):\n",
    "    res = np.zeros(shape = (vocab_size))\n",
    "    res[x] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:05.900318Z",
     "start_time": "2018-07-09T02:33:04.086785Z"
    }
   },
   "outputs": [],
   "source": [
    "x_1 = np.array([np.sum(np.array([one_hot(word, MAX_FEATURES) for word in example]), axis = 0) for example in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data process - tr/va split and define iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:08.625731Z",
     "start_time": "2018-07-09T02:33:08.540505Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_idx = np.random.choice(range(x_1.shape[0]), int(x_1.shape[0] * .8))\n",
    "va_idx = [x for x in range(x_1.shape[0]) if x not in tr_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:10.348133Z",
     "start_time": "2018-07-09T02:33:10.302009Z"
    }
   },
   "outputs": [],
   "source": [
    "tr_x = x_1[tr_idx, :]\n",
    "tr_y = [y[i] for i in tr_idx]\n",
    "va_x = x_1[va_idx, :]\n",
    "va_y = [y[i] for i in va_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-09T02:33:19.035519Z",
     "start_time": "2018-07-09T02:33:19.031513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5668, 2000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "* If we transform sentence into machine-understandable form via average of BOW, we can separate representation and classification\n",
    "* Here, we will apply various classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:20:27.240271Z",
     "start_time": "2018-06-16T16:20:27.222750Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:21:45.266083Z",
     "start_time": "2018-06-16T16:21:24.711438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(tr_x, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:22:11.861052Z",
     "start_time": "2018-06-16T16:22:11.679670Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb.predict(va_x)\n",
    "pred_xgb = [round(val) for val in y_pred_xgb]\n",
    "\n",
    "# Check predictions\n",
    "#pred_pd= pd.DataFrame(pred_xgb, columns = ['pred']).reset_index()\n",
    "#pred_pd.groupby(['pred']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:22:54.227408Z",
     "start_time": "2018-06-16T16:22:54.219056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.76%\n"
     ]
    }
   ],
   "source": [
    "accuracy_xgb = accuracy_score(va_y, pred_xgb)\n",
    "print('Accuracy: %.2f%%'%(accuracy_xgb * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:22:59.099704Z",
     "start_time": "2018-06-16T16:22:59.064160Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:23:02.455789Z",
     "start_time": "2018-06-16T16:23:02.046982Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(tr_x, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:23:04.872970Z",
     "start_time": "2018-06-16T16:23:04.813480Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_rf = rf.predict(va_x)\n",
    "pred_rf = [round(val) for val in y_pred_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:23:06.935466Z",
     "start_time": "2018-06-16T16:23:06.927963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.08%\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf = accuracy_score(va_y, pred_rf)\n",
    "print('Accuracy: %.2f%%'%(accuracy_rf * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:23:08.901361Z",
     "start_time": "2018-06-16T16:23:08.897570Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:27:36.872185Z",
     "start_time": "2018-06-16T16:27:36.865713Z"
    }
   },
   "outputs": [],
   "source": [
    "models = (svm.SVC(kernel = 'linear', C = 1.0), # C: SVM Regularization parameter\n",
    "          svm.LinearSVC(C = 1.0),\n",
    "          svm.SVC(kernel = 'rbf', gamma = .7, C = 1.0),\n",
    "          svm.SVC(kernel = 'poly', degree = 3, C = 1.0)\n",
    ")\n",
    "\n",
    "models = (mdl.fit(tr_x, tr_y) for mdl in models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:30:16.093817Z",
     "start_time": "2018-06-16T16:27:40.386965Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_svm = (mdl.predict(va_x) for mdl in models)\n",
    "pred_svm = [[round(val) for val in _pred] for _pred in y_pred_svm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:31:25.546462Z",
     "start_time": "2018-06-16T16:31:25.528584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [99.34 99.27 93.79 57.41]\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm = [accuracy_score(va_y, pred) for pred in pred_svm]\n",
    "print('Accuracy: {}'.format(np.round(accuracy_svm, 4)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:35:16.199066Z",
     "start_time": "2018-06-16T16:35:16.144108Z"
    }
   },
   "outputs": [],
   "source": [
    "va_txt = pd.DataFrame(np.array([origin_txt[idx] for idx in va_idx]), columns = ['txt'])\n",
    "pred_rf_pd = pd.DataFrame(pred_rf, columns  = ['pred_rf'])\n",
    "pred_xgb_pd = pd.DataFrame(pred_xgb, columns  = ['pred_xgb'])\n",
    "pred_svm_svc_pd = pd.DataFrame(pred_svm[2], columns  = ['pred_svm'])\n",
    "label_pd = pd.DataFrame(va_y, columns = ['label'])\n",
    "result = pd.concat([va_txt, pred_rf_pd, pred_xgb_pd, pred_svm_svc_pd, label_pd], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:35:17.654932Z",
     "start_time": "2018-06-16T16:35:17.639960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>pred_rf</th>\n",
       "      <th>pred_xgb</th>\n",
       "      <th>pred_svm</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I liked the Da Vinci Code but it ultimatly did...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that's not even an exaggeration ) and at midni...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I loved the Da Vinci Code, but now I want some...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i thought da vinci code was great, same with k...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Da Vinci Code is actually a good movie...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt  pred_rf  pred_xgb  \\\n",
       "0  I liked the Da Vinci Code but it ultimatly did...        0         1   \n",
       "1  that's not even an exaggeration ) and at midni...        1         0   \n",
       "2  I loved the Da Vinci Code, but now I want some...        1         1   \n",
       "3  i thought da vinci code was great, same with k...        1         0   \n",
       "4      The Da Vinci Code is actually a good movie...        1         0   \n",
       "\n",
       "   pred_svm  label  \n",
       "0         1      1  \n",
       "1         1      1  \n",
       "2         1      1  \n",
       "3         1      1  \n",
       "4         1      1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:35:20.710584Z",
     "start_time": "2018-06-16T16:35:20.698418Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of error case 61\n",
      "# of error case 71\n",
      "# of error case 197\n"
     ]
    }
   ],
   "source": [
    "print('# of error case {}'.format(result[result['pred_rf'] != result['label']].shape[0]))\n",
    "print('# of error case {}'.format(result[result['pred_xgb'] != result['label']].shape[0]))\n",
    "print('# of error case {}'.format(result[result['pred_svm'] != result['label']].shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN with embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:11.580851Z",
     "start_time": "2018-06-16T16:38:11.082714Z"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn\n",
    "context = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:12.303080Z",
     "start_time": "2018-06-16T16:38:12.297603Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self, input_dim, emb_dim, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.embed = nn.Embedding(input_dim = input_dim, output_dim = emb_dim)\n",
    "            self.dense1 = nn.Dense(64)\n",
    "            #self.dense2 = nn.Dense(32, activation = 'relu')\n",
    "            self.bn = nn.BatchNorm()\n",
    "            self.dense2 = nn.Dense(2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn(x)\n",
    "        x = nd.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:13.587224Z",
     "start_time": "2018-06-16T16:38:13.582092Z"
    }
   },
   "outputs": [],
   "source": [
    "def acc_f(label, pred):\n",
    "    pred = pred.ravel()\n",
    "    label = label.ravel()\n",
    "    #print('pred = {}'.format(pred))\n",
    "    #print('label = {}'.format(label))\n",
    "    corr = ((pred > 0.5) == label)*1.\n",
    "    return (((pred > 0.5) == label)*1.).mean()\n",
    "tr_metric = mx.metric.CustomMetric(acc_f)\n",
    "va_metric = mx.metric.CustomMetric(acc_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:20.656050Z",
     "start_time": "2018-06-16T16:38:20.647311Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "batch_size = 64\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "os.environ['MXNET_ENGINE_TYPE'] = 'NaiveEngine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T16:38:31.105063Z",
     "start_time": "2018-06-16T16:38:30.894757Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = mx.io.NDArrayIter(data=[tr_x, tr_y], batch_size=batch_size, shuffle = False)\n",
    "valid_data = mx.io.NDArrayIter(data=[va_x, va_y], batch_size=batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T16:39:22.206Z"
    }
   },
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[21:45:50] src/ndarray/ndarray.cc:1233: GPU is not enabled\n\nStack trace returned 10 entries:\n[bt] (0) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1d00c2) [0x7f7ba24440c2]\n[bt] (1) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1d06c8) [0x7f7ba24446c8]\n[bt] (2) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2a0d883) [0x7f7ba4c81883]\n[bt] (3) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x28d4ce8) [0x7f7ba4b48ce8]\n[bt] (4) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x28d9e07) [0x7f7ba4b4de07]\n[bt] (5) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x28da7e3) [0x7f7ba4b4e7e3]\n[bt] (6) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x27fd86b) [0x7f7ba4a7186b]\n[bt] (7) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7f7ba4a71e2f]\n[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f7d0bee8e40]\n[bt] (9) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb) [0x7f7d0bee88ab]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-ebeffc8063e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_FEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXavier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmaxCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, init, ctx, verbose, force_reinit)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m             \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_reinit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_reinit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, init, ctx, default_init, force_reinit)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deferred_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finish_deferred_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36m_finish_deferred_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m                     initializer.InitDesc(self.name, {'__init__': init}), data)\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36m_init_impl\u001b[0;34m(self, data, ctx_list)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mdev_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/gluon/parameter.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mdev_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ctx_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36mcopyto\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m             \u001b[0mhret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNDArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_new_alloc_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'copyto does not support type '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/ndarray/register.py\u001b[0m in \u001b[0;36m_copyto\u001b[0;34m(data, out, name, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/_ctypes/ndarray.py\u001b[0m in \u001b[0;36m_imperative_invoke\u001b[0;34m(handle, ndargs, keys, vals, out)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mc_str_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         ctypes.byref(out_stypes)))\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moriginal_output\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [21:45:50] src/ndarray/ndarray.cc:1233: GPU is not enabled\n\nStack trace returned 10 entries:\n[bt] (0) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1d00c2) [0x7f7ba24440c2]\n[bt] (1) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x1d06c8) [0x7f7ba24446c8]\n[bt] (2) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x2a0d883) [0x7f7ba4c81883]\n[bt] (3) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x28d4ce8) [0x7f7ba4b48ce8]\n[bt] (4) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x28d9e07) [0x7f7ba4b4de07]\n[bt] (5) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x28da7e3) [0x7f7ba4b4e7e3]\n[bt] (6) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(+0x27fd86b) [0x7f7ba4a7186b]\n[bt] (7) /home/kookmin/py_libs/lib/python3.6/site-packages/mxnet/libmxnet.so(MXImperativeInvokeEx+0x6f) [0x7f7ba4a71e2f]\n[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f7d0bee8e40]\n[bt] (9) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x2eb) [0x7f7d0bee88ab]\n\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(input_dim = MAX_FEATURES, emb_dim = 50)\n",
    "mlp.collect_params().initialize(mx.init.Xavier(), ctx = context)\n",
    "loss = gluon.loss.SoftmaxCELoss()\n",
    "trainer = gluon.Trainer(mlp.collect_params(), 'adam', {'learning_rate': 1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm_notebook(range(n_epoch), desc = 'epoch'):\n",
    "    ## Training\n",
    "    train_data.reset()\n",
    "    n_obs = 0\n",
    "    _total_los = 0\n",
    "    pred = []\n",
    "    label = []\n",
    "    for i, batch in enumerate(train_data):\n",
    "        _dat = batch.data[0].as_in_context(context)\n",
    "        _label = batch.data[1].as_in_context(context)\n",
    "        with autograd.record():\n",
    "            _out = mlp(_dat)\n",
    "            _los = nd.sum(loss(_out, _label)) # 배치의 크기만큼의 loss가 나옴\n",
    "            _los.backward()\n",
    "        trainer.step(_dat.shape[0])\n",
    "        n_obs += _dat.shape[0]\n",
    "        #print(n_obs)\n",
    "        _total_los += nd.sum(_los).asnumpy()\n",
    "        # Epoch loss를 구하기 위해서 결과물을 계속 쌓음\n",
    "        pred.extend(nd.softmax(_out)[:,1].asnumpy()) # 두번째 컬럼의 확률이 예측 확률\n",
    "        label.extend(_label.asnumpy())\n",
    "    #print(pred)\n",
    "    #print([round(p) for p in pred]) # 기본이 float임\n",
    "    #print(label)\n",
    "    #print('**** ' + str(n_obs))\n",
    "    #print(label[:10])\n",
    "    #print(pred[:10])\n",
    "    #print([round(p) for p in pred][:10])\n",
    "    tr_acc = accuracy_score(label, [round(p) for p in pred])\n",
    "    tr_loss = _total_los/n_obs\n",
    "    \n",
    "    ### Evaluate training\n",
    "    valid_data.reset()\n",
    "    n_obs = 0\n",
    "    _total_los = 0\n",
    "    pred = []\n",
    "    label = []\n",
    "    for i, batch in enumerate(valid_data):\n",
    "        _dat = batch.data[0].as_in_context(context)\n",
    "        _label = batch.data[1].as_in_context(context)\n",
    "        _out = mlp(_dat)\n",
    "        _pred_score = nd.softmax(_out)\n",
    "        n_obs += _dat.shape[0]\n",
    "        _total_los += nd.sum(loss(_out, _label)).asnumpy()\n",
    "        pred.extend(nd.softmax(_out)[:,1].asnumpy())\n",
    "        label.extend(_label.asnumpy())\n",
    "    va_acc = accuracy_score(label, [round(p) for p in pred])\n",
    "    va_loss = _total_los/n_obs\n",
    "    tqdm.write('Epoch {}: tr_loss = {}, tr_acc= {}, va_loss = {}, va_acc= {}'.format(epoch, tr_loss, tr_acc, va_loss, va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp = mlp(nd.array(va_x, ctx = context))\n",
    "# softmax를 적용하고\n",
    "# 두번째 열을 뽑아와서\n",
    "# nd.round 함수를 적용해서 0/1 예측값을 얻고\n",
    "# numpy array로 바꾸고\n",
    "# 첫번째 원소를 뽑아서 예측 label로 사용\n",
    "pred_mlp = [nd.round(val).asnumpy()[0] for val in nd.softmax(y_pred_mlp)[:, 1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mlp = accuracy_score(va_y, pred_mlp)\n",
    "print('Accuracy: %.2f%%'%(accuracy_rf * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN without embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense1 = nn.Dense(64)\n",
    "            #self.dense2 = nn.Dense(32, activation = 'relu')\n",
    "            self.bn = nn.BatchNorm()\n",
    "            self.dense2 = nn.Dense(2)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn(x)\n",
    "        x = nd.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "batch_size = 64\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_no_embedding = MLP()\n",
    "mlp_no_embedding.collect_params().initialize(mx.init.Xavier(), ctx = context)\n",
    "loss = gluon.loss.SoftmaxCELoss()\n",
    "trainer = gluon.Trainer(mlp_no_embedding.collect_params(), 'adam', {'learning_rate': 1e-3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm_notebook(range(n_epoch), desc = 'epoch'):\n",
    "    ## Training\n",
    "    train_data.reset()\n",
    "    n_obs = 0\n",
    "    _total_los = 0\n",
    "    pred = []\n",
    "    label = []\n",
    "    for i, batch in enumerate(train_data):\n",
    "        _dat = batch.data[0].as_in_context(context)\n",
    "        _label = batch.data[1].as_in_context(context)\n",
    "        with autograd.record():\n",
    "            _out = mlp_no_embedding(_dat)\n",
    "            _los = nd.sum(loss(_out, _label)) # 배치의 크기만큼의 loss가 나옴\n",
    "            _los.backward()\n",
    "        trainer.step(_dat.shape[0])\n",
    "        n_obs += _dat.shape[0]\n",
    "        #print(n_obs)\n",
    "        _total_los += nd.sum(_los).asnumpy()\n",
    "        # Epoch loss를 구하기 위해서 결과물을 계속 쌓음\n",
    "        pred.extend(nd.softmax(_out)[:,1].asnumpy()) # 두번째 컬럼의 확률이 예측 확률\n",
    "        label.extend(_label.asnumpy())\n",
    "    #print(pred)\n",
    "    #print([round(p) for p in pred]) # 기본이 float임\n",
    "    #print(label)\n",
    "    #print('**** ' + str(n_obs))\n",
    "    #print(label[:10])\n",
    "    #print(pred[:10])\n",
    "    #print([round(p) for p in pred][:10])\n",
    "    tr_acc = accuracy_score(label, [round(p) for p in pred])\n",
    "    tr_loss = _total_los/n_obs\n",
    "    \n",
    "    ### Evaluate training\n",
    "    valid_data.reset()\n",
    "    n_obs = 0\n",
    "    _total_los = 0\n",
    "    pred = []\n",
    "    label = []\n",
    "    for i, batch in enumerate(valid_data):\n",
    "        _dat = batch.data[0].as_in_context(context)\n",
    "        _label = batch.data[1].as_in_context(context)\n",
    "        _out = mlp(_dat)\n",
    "        _pred_score = nd.softmax(_out)\n",
    "        n_obs += _dat.shape[0]\n",
    "        _total_los += nd.sum(loss(_out, _label)).asnumpy()\n",
    "        pred.extend(nd.softmax(_out)[:,1].asnumpy())\n",
    "        label.extend(_label.asnumpy())\n",
    "    va_acc = accuracy_score(label, [round(p) for p in pred])\n",
    "    va_loss = _total_los/n_obs\n",
    "    tqdm.write('Epoch {}: tr_loss = {}, tr_acc= {}, va_loss = {}, va_acc= {}'.format(epoch, tr_loss, tr_acc, va_loss, va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mlp_no_embedding = mlp_no_embedding(nd.array(va_x, ctx = context))\n",
    "# softmax를 적용하고\n",
    "# 두번째 열을 뽑아와서\n",
    "# nd.round 함수를 적용해서 0/1 예측값을 얻고\n",
    "# numpy array로 바꾸고\n",
    "# 첫번째 원소를 뽑아서 예측 label로 사용\n",
    "pred_mlp_no_embedding = [nd.round(val).asnumpy()[0] for val in nd.softmax(y_pred_mlp)[:, 1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_mlp_no_embedding = accuracy_score(va_y, pred_mlp_no_embedding)\n",
    "print('Accuracy: %.2f%%'%(accuracy_rf * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_txt = pd.DataFrame(np.array([origin_txt[idx] for idx in va_idx]), columns = ['txt'])\n",
    "pred_mlp_no_embedding_pd = pd.DataFrame(pred_mlp_no_embedding, columns  = ['pred_mlp_no_embedding'])\n",
    "label_pd = pd.DataFrame(va_y, columns = ['label'])\n",
    "result = pd.concat([va_txt, pred_mlp_no_embedding_pd, label_pd], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result['pred_mlp_no_embedding'] != result['label']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pred_score[:, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
